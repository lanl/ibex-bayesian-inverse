\documentclass[12pt]{article}
\usepackage[ruled, vlined]{algorithm2e}
\usepackage{amsmath, amsfonts, amssymb, mathrsfs}
\usepackage{caption}
\usepackage{dcolumn}
\usepackage{filemod}
\usepackage{floatrow}
\usepackage{gensymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{natbib}
\usepackage{setspace}
\usepackage{subcaption}
\usepackage{verbatim}
\usepackage{makecell}

\oddsidemargin=0.25in
\evensidemargin=0.25in
\textwidth=7in
\textheight=8.75in
\topmargin=-.5in
\addtolength{\oddsidemargin}{-.5in}
\addtolength{\evensidemargin}{-.5in}
\footskip=0.5in

\begin{document}

\title{Bayesian Statistical Inversion for High-Dimensional Computer Model
Output and Spatially Distributed Counts}
\author{Steven D. Barnett\thanks{Corresponding author
\href{mailto:sdbarnett@vt.edu}{\tt sdbarnett@vt.edu}, Department of
Statistics, Virginia Tech} \and Robert B. Gramacy\thanks{Department of
Statistics, Virginia Tech} \and Lauren J. Beesley\thanks{Statistical Sciences
Group, Los Alamos National Laboratory} \and Dave Osthus\footnotemark[3] \and
Yifan Huang\thanks{ Nuclear and Particle Physics, AstroPhysics and Cosmology,
Los Alamos National Laboratory} \and Fan Guo\footnotemark[4] \and Eric J.
Zirnstein\thanks{ Department of Astrophysical Sciences, Princeton University}
\and Daniel B. Reisenfeld\thanks{Space Science and Applications Group, Los
Alamos National Laboratory}}
\date{}

\maketitle

%\vspace{-0.5cm}

\begin{abstract}
Data collected by the Interstellar Boundary Explorer (IBEX) satellite,
recording heliospheric energetic neutral atoms (ENAs), exhibit a phenomena
that have caused space scientists to revise hypotheses about the physical
processes, and computer simulations under those models, in play at the
boundary of our solar system.  Evaluating the fit of these computer models
involves tuning their parameters to observational data from IBEX. This would
be a classic (Bayesian) inverse problem if not for three challenges: (1) the
computer simulations are slow, limiting the size of campaigns of runs; so (2)
surrogate modeling is essential but outputs are high-resolution images
thwarting conventional methods; and (3) IBEX observations are counts, whereas
most inverse problem techniques assume Gaussian field data. To fill that gap
we propose a novel approach to Bayesian inverse problems coupling a Poisson
response with a sparse Gaussian process surrogate using the Vecchia
approximation.  We demonstrate the capibilities of our proposed framework,
which compare favorably to alternatives, through multiple simulated
examples in terms of recovering ``true'' computer model parameters and accurate
out-of-sample prediction. We then apply this new technology to IBEX satellite
data and associated computer models developed at Los Alamos National Lab.

\bigskip
\noindent \textbf{Key words:} Gaussian process, surrogate modeling,
Poisson, calibration, heliospheric science, IBEX, Vecchia approximation
\end{abstract}

\doublespacing % no double spacing for arXiv

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
\label{sec:intro}

%% IBEX
%% - Talk about the satellite
%% - Explain the mission
%% - Introduce the idea of a computer model
%% - Explain desire to understand the distribution of parameters
The National Aeronautics and Space Administration (NASA) launched the
Interstellar Boundary Explorer (IBEX) satellite in 2008 as part of their Small
Explorer program \citep{mccomas2009aIBEX} to deepen our understanding of the
heliosphere. The heliosphere is the bubble formed by the solar wind that
encompasses our solar system and acts as a barrier to interstellar space. Of
particular interest is the behavior at the edge of the heliosphere, known as
the heliopause. Here, highly energized hydrogen ions that make up the solar
wind interact with neutral atoms, occasionally undergo electro exchange, and
become neutral themselves. These energetic neutral atoms (ENAs) are unaffected
by magnetic fields and therefore travel in a straight line.

Some ENAs eventually make their way to Earth and can be detected by an
instrument on the IBEX satellite called the IBEX-Hi ENA imager
\citep{funsten2009IBEXHiENA}. This apparatus records the energy level and
approximate location of origin for each ENA that enters the detector. IBEX's
raw collected data consist of ENA counts and exposure times for each area of
the sky at which the satellite points, providing sufficient information to
estimate the rate at which these particles are created throughout the
heliopause. An example of this estimated surface or image, referred to by
space scientists as a \textit{sky map}, can be found in the left panel of Fig.
\ref{f:fig1}. Sky maps are integral to better understand the heliosphere's
creation and evolution.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.75,trim=0 0 65 0,clip=TRUE]{ibex_real1.pdf}
\includegraphics[scale=0.75,trim=35 0 65 0,clip=TRUE]{sim1.pdf}
\includegraphics[scale=0.75,trim=35 0 20 0,clip=TRUE]{sim2.pdf}
\caption{Observed ENA rate detected by the
IBEX satellite (left) and output from two IBEX  simuations under
different parameter settings (middle, right).
\label{f:fig1}}
\end{figure}

One can think of the heliosphere as a ``boat'' moving through interstellar
space. At the outset of IBEX's mission, scientists expected to see an elevated
rate of ENAs being generated at the front (nose) and back (tail), much like
the turbulent interaction with water at a boat's bow and stern. And indeed,
that belief was validated by IBEX data. These predicted regions of raised ENA
rates are known as \textit{globally distributed flux}, or GDF. At the nose and
tail there are an increased number of collisions between hydrogen ions and
neutral particles in the interstellar medium.

However, in a completely unanticipated finding, IBEX also recorded a thin
string of higher rates of ENAs \citep{fuselier2009IBEXribbon} wrapping around
the heliosphere. Scientists now refer to this phenomenom as the
\textit{ribbon}. This unique feature of a sky map is clearly visible in Fig.
\ref{f:fig1}. Since this discovery, space scientists have proposed several
theories attempting to describe the physical process that generates the ribbon
\citep{mccomas2014ibex, zirnstein2018role, zirnstein2019strong,
zirnstein2021dependence}.

Computer models encapsulating competing theories have been built which
generate high-resolution (i.e, a high-dimensional response) synthetic sky maps
(middle and right panels of Figure \ref{f:fig1}). These simulations are
extremely sophisticated and involve many complex and expensive operations,
such as the solving of partial differential equations. Consequently, executing
a single run of the computer model at a specified set of model parameters can
take thousands of core hours.  This severely limits the number of unique 
runs generating simulated sky in various conditions. 

Our work here focuses on two, publicly accessible computer models: a GDF
model proposed by \citet{zirnstein2021heliosheath}; and a ribbon-only model
developed by \citet{zirnsteinGDFsims2015}. These simulators take inputs that
can be varied to modify the shape and intensity of both ribbon and GDF. The
ribbon-only model relies on two parameters, \textit{parallel mean free path}
and \textit{ratio}, while the GDF model takes \textit{kappa} and
\textit{pickup ions (PUI) cooling index} as inputs. Dialing in good settings
for these input parameters, in light of observed ENA counts from IBEX, is
instrumental in furthering theory development and validation.

Space scientists at Los Alamos National Lab (LANL) wish to solve this ``parameter
tuning'' exercise as a Bayesian inverse problem
\citep{kaipio2011bayesian,stuart2010inverse,knapik2011bayesian}, obtaining a
posterior distribution over likely settings.  However, the exposure and count data
IBEX provides, along with computer simulated rates, present some unique challenges:
1) computationally intensive models limiting simulation, necessitating surrogate
modeling; 2) high-dimensional model output (simulated sky maps, each containing
tens of thousands of pixels), thwarting conventional surrogate modeling
techniques; 3) a non-Gaussian field response (Poisson counts).  It is worth noting
that Bayesian posterior sampling, say via Markov chain Monte Carlo (MCMC),
compounds computational bottlenecks (2). We propose a framework for Bayesian
inverse problems that utilizes the Vecchia approximation
\citep{katzfuss2021general,scaledvecchiakatzfuss2022} with a Gaussian process (GP)
surrogate or emulator for high dimensional computer simulations, and couple that
with a Poisson observational model to furnish posterior samples of unknown
parameters to these models given observed data.

Methods exist separately, in the literature, to address needs in each of the
aforementioned situations 1)--3), but we are not aware of anything in the
intersection. Table \ref{tab:prev_work} summarizes the features of the IBEX inverse
problem and reviews the necessary capabilities, alongside recent papers offering
partial solutions.  References provided are representative.  We acknowledge that
there are, in most cases, several works that may fit the bill.  Each row in the table
may be summarized as follows.

\begin{table}[ht!]
\centering
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{|l|c|c|c|c|}
\hline
& Bayesian & \makecell{Non-\\Gaussian} & \makecell{Large-Scale \\ Simulation \\ Output} & \makecell{High-Dim \\ Response} \\
\hline
Our Contribution & \checkmark & \checkmark & \checkmark & \checkmark \\
\hline
\citet{kennedyohagan2001} & \checkmark & & & \\
\hline
\citet{higdoncalib2008} & \checkmark & & & \checkmark \\
\hline
\citet{gramacy2015calibrating} & & & \checkmark & \\
\hline
\citet{grosskopfcountcalib2020} & \checkmark & \checkmark & & \\
\hline
\end{tabular}
\caption{Check marks indicate that functionality exists within the cited paper and/or
accompanying software. To save space, only one citation is listed for each
row.}
\label{tab:prev_work}
\end{table}

\citet{kennedyohagan2001} offer the canonical computer model calibration
framework, which provides a fully Bayesian approach to estimate the posterior
distribution of calibration parameters and improve prediction at new,
unobserved field locations. However, their methodology is limited to Gaussian
field observations and small, simulator output. \citet{higdoncalib2008} and
SEPIA \citep{gattiker2020lanl}, its more recent incarnation, also employ
Bayesian methods while accounting for computer model output that is
functional. But SEPIA is somewhat rigid, does not scale well with added model
runs, and requires the user to specify a number of basis functions to
represent the simulator response. \citet{gramacy2015calibrating} consider
computer model calibration with large-scale output from a computer experiment,
necessitating an approximation. But their implementation is not Bayesian and
the scale of simulator data is still orders of magnitude less than IBEX.
\citet{grosskopfcountcalib2020} provide an extension of the Kennedy \& O'Hagan
(hereafter referred to as KOH) framework to non-Gaussian data that maintains a
Bayesian approach. But they are limited to small amounts of computer model
data and do not consider higher dimensional responses. In contrast, our
approach checks all the boxes to achieve the goal of IBEX space scientists and
therefore applies to a wider class of problems than previous work.

Our integrated framework for Bayesian inverse problems overcomes these obstacles
together in an all-in-one solution, as illustrated in the top row of Table
\ref{tab:prev_work}. We adopt the approach of generalized computer model calibration,
adapting to IBEX's count data with a Poisson likelihood and employing MCMC to garner
posterior samples of model parameters, which determine the underlying mean of our
Poisson model, given observed data. These samples allow us to estimate the full joint
posterior distribution of the unknown parameters. We access predicted ENA rates
through a GP surrogate or emulator fit to a limited set of expensive,
high-dimensional IBEX computer simulations to more thoroughly explore the domain of
possible sky maps that serves as the basis for the observed ENA counts. As previously
stated, MCMC exacerbates the computational burden of making surrogate predictions,
necessitating not only a sparse GP surrogate, but one that can swiftly generate
repeated sky map proposals at each MCMC iteration. We find the Vecchia approximation
to be extremely effective in this regard. Lastly, we propose a more intuitive
technique to modeling high-dimensional vectors, treating each pixel representing an
ENA rate as a scalar response of interest. This differs from previous approaches to
functional computer model output, but enables us to leverage recent advances in
sparse GP surrogate modeling. Additionally, using this strategy efficiently scales
both to increased dimensionality of the response and to larger sizes of training
sets.

%% OUTLINE
%% - Review Bayesian Inverse Problems, GP Surrogates, SEPIA
%% - Introduce our framework
%% - Explain use of Vecchia approximation
%% - Demonstrate on simulated data
%% - Apply to real IBEX data
Our paper is laid out as follows. First, Section \ref{sec:review} reviews methods
that form the foundation for our work, namely Bayesian Inverse Problems and Gaussian
process surrogate models. We also give a brief description of the methodology and
implementation behind SEPIA, which could be classified as the current ``status quo''
in Bayesian Inverse Problems for high-dimensional computer model output. In Section
\ref{sec:gen_bayes_inv} we introduce our framework for solving the inverse problem in
non-Gaussian contexts. Section \ref{sec:vecchia} describes our use of the Vecchia
approximation to stretch the capacity of a GP surrogate beyond small simulator
training runs. In Section \ref{sec:sims}, we illustrate the effectiveness of our
framework in discovering the true, underlying model parameters on simulated data from
the IBEX computer model. We then return to our motivating application and apply our
methods to the raw IBEX satellite data in Section \ref{sec:ibex_real}. To conclude,
we discuss any extensions and future work in Section \ref{sec:discuss}. Our
implementation may be found at \url{https://github.com/lanl/IBEX_Calibration} along
with code reproducing all included examples.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% SECTION 2: Review:
\section{Bayesian inverse problems}
\label{sec:review}

We study IBEX through the lens of observational data $Y^F$ ($F$ for field
measurement) and a computer implementation of a physical model $m(u, X)$,
where parameters $u$ are unknown and $X$ represents the spatial locations
where the simulation output is evaluated.  These may be the locations $X^F$
that correspond to field measurements $Y^F$, or a grid of predictive locations
supporting high resolution visuals.  Given prior information about $u$, we
want to know which $u$'s lead to realizations of $m(\cdot, \cdot)$ that could
explain $Y^F$, i.e., the posterior for $u \mid Y^F$. 

This is a classic Bayesian inverse problem
\citep{kaipio2011bayesian,stuart2010inverse,knapik2011bayesian}. Eq.~\ref{eq:inv_bayes_mod} 
provides the typical hierarchical model used in this
setting.
\begin{align}
Y^F &\sim \mathcal{N}_{n_F}\!\left(\mu\!\left(X^F\right),
\Sigma\!\left(X^F\right)\right) \nonumber  \\
\mu(X) &= m(u, X) \label{eq:inv_bayes_mod} \\
\Sigma(X) &\sim \pi\left(\Sigma\right) & \mbox{e.g.,} \quad \Sigma^{-1} & \sim \mathrm{Wishart}((\rho V)^{-1}, \rho)
\nonumber \\
u &\sim \pi(u) & \mbox{e.g.,} \quad u &\sim \mathrm{Unif}[0,1]^p \nonumber
\end{align}
One big difference with Bayesian inverse problems, as opposed to ordinary
Bayesian inference, is that the parameters $\mu(X^F)$ and $\Sigma(X^F)$
defining the distribution of $Y^F$ are not of direct interest. Rather, we are
interested in settings $u$ that define
$\mu(X)$ and $\Sigma(X)$ through $m(u, X)$.  For example, two different
settings of $u$ were used in the IBEX simulator to generate the center and
right panels of Figure \ref{f:fig1}. Colors indicate output $\mu(X)$ values on
a dense grid $X$ of longitudes and latitudes. We are interested in learning
which $u$ are likely to have generated the recorded $Y^F$ values in the left
panel, observed at locations where the IBEX satellite was pointed ($X^F$) to
collect particles.

To help fix ideas, consider the simpler example introduced in the left panel
of Figure \ref{f:toy_calib}. Red stars indicate noisy field measurements,
$Y^F$, observed in replicate as $y_i \stackrel{\mathrm{iid}} \sim
\mathcal{N}(m(u^\star, x_i), \sigma^2)$ for a ``true'' unknown $u^\star =
(u_1^\star, u_2^\star)^\top$ and uniform $x_i \in X^F$.  In this simple
example, the computer model $m(\cdot, \cdot)$ was used to generate the data.
In practice, the model represents a caricature using known or best-guess
physics. Each light gray line is a realization of $m(\cdot, \cdot)$ for a
different $u$ on a fine grid of spatial locations $X$. The bold-black-dashed
line is $m(u^\star, X)$ provided as a reference.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.55,trim=20 0 30 0,clip=TRUE]{logit1_obs.pdf}
\includegraphics[scale=0.55,trim=59 0 30 0,clip=TRUE]{logit1_est.pdf}
\includegraphics[scale=0.55,trim=16 0 30 0,clip=TRUE]{logit1_post_draws.pdf}
\caption{A simple inverse problem. Field observations and a small sample of
computer model runs (left), model evaluations at posterior draws and mean
(middle), and posterior distribution of model parameters (right).
\label{f:toy_calib}}
\end{figure}

The middle panel of the figure shows runs of our virtual model evaluated at posterior
draws of $u$ obtained under Metropolis sampling using a multivariate
normal likelihood whose mean $\mu(X^F)=m(u^{(t)}, X^F)$ and whose covariance $\Sigma(X^F) \sim \sigma^2
\mathbb{I}$, where $\sigma^2$ is marginalized out under a reference prior
$\pi(\sigma^2) \propto 1/\sigma^2$. Although we display these runs on a
high-resolution grid $X$, the sampler only uses evaluations of $m(u^{(t)}, X^F)$ in
likelihood evaluations. The posterior samples of $u$ thus obtained are shown
in the right panel of the figure.  In this toy example, it is evident that the
Metropolis sampler successfully concentrates posterior mass around the true
value of $u$.

The literature on Bayesian inverse problems involves methods that work
predominantly in this way, particularly as regards a Gaussian likelihood. We
aim to provide a method that achieves the same goal, but for unknown parameters
$u$ that underlie observed IBEX satellite data (left panel of Figure
\ref{f:fig1}), whose observations are counts under variable exposure. Our first
contribution, which is albeit rather straightforward, is to depart from that
literature by perusing a Poisson likelihood.

%------------------------------------------------------------------------------
%% SECTION 2.1 - Generalized Bayesian inverse problems
\subsection{Generalized Bayesian inverse problems}
\label{sec:gen_bayes_inv}
%------------------------------------------------------------------------------

Computer simulations are not limited to modeling physical processes that
generate a Gaussian or continuous response. For instance, a field experiment may
return a binary response and a corresponding computer model outputs the
probability of success or failure at each location. Categorical responses may
expand beyond two classes, representing a multinomial response. In this paper we
focus on Poisson-distributed counts in the field and an associated simulator
whose response represents the mean function $\lambda(X)$, but our framework can
easily be generalized to any type of response. To do this, we extend
Eq.~\ref{eq:inv_bayes_mod} by modeling counts detected by IBEX as
\begin{align}
Y^F &\sim \mathrm{Pois}(\lambda(X^F), e(X^F)) \nonumber  \\
\lambda(X) &= m(u, X) \label{eq:inv_bayes_pois} \\
u &\sim \pi(u), & \mbox{e.g.,} \quad u &\sim \mathrm{Unif}[0,1]^p \nonumber
\end{align}
where $e(X^F)$ represents exposure time, or the duration the satellite points at
specific locations in the sky. $\lambda(X^F)$ denotes the rate at which
ENA particles are generated for rows (latitude/longitude pairs) in $X^F$. We
note that it is common to assume unit exposure ($e(\cdot)=1$) when working with
count data. However, in our application each data point is a total count of
particles observed over a series of different time intervals.

As mentioned previously, we (or the scientists we collaborate with) are not
focused on the posterior distribution of $\lambda(X)$. Instead, we aim to
understand the posterior $u \mid Y^F$, where $\lambda(X^F)$ is determined by a
computer simulation $m(\cdot,\cdot)$. We utilize MCMC to sample from the
posterior, similar to our solution in Figure \ref{f:toy_calib}. The main
distinction is the evaluation of the likelihood. For the IBEX field data, we
evaluate a Poisson likelihood given an exposure time for each observation and a
mean surface determined by a simulator $m(\cdot,\cdot)$ at proposed values of
$u$. Our approach is summarized in our first algorithm.
\begin{algorithm}[ht]
\DontPrintSemicolon
Initialize $u^{(0)}$. \\
Set $\lambda(X^F)^{(0)} = m(u^{(0)}, X^F)$. \\
\For{$t = 1, \dots, T$}{
  Propose new model parameters $u^{(t)} \mid u^{(t-1)}$ via MH, \\
  Evaluate simulator at field locations: $\lambda(X^F)^{(t)} = m(u^{(t)}, X^F)$, \\
  Calculate $\mathcal{L}(Y^F|\lambda(X^F)^{(t)}, e(X^F))$, \\
  Accept or reject $u^{(t)}$.
  }
\caption{MCMC (Metropolis-within-Gibbs) for Poisson Bayesian inverse problems}
\label{alg:gibbs}
\end{algorithm}

Using Algorithm \ref{alg:gibbs}, we can build on the toy problem we introduced
in Figure \ref{f:toy_calib} and align it more closely with the IBEX data.
Instead of observing a mean process $\mu(X^F)$ with random, Gaussian noise,
suppose we are given counts, drawn from a Poisson process with $\lambda(X^F) =
m(u^*, X^F)$, as shown in the left panel of Figure \ref{f:toy_calib_pois}.
Computer model runs $m(\cdot,\cdot) = \lambda(X)$ produce different mean
surfaces given unique values of $u = (u_1, u_2)$. Observed counts are shown as
red stars. Each observation also has an associated exposure time $e(\cdot)$. Red
circles indicate the sum of all counts at one input location (i.e, a single row
of $X^F$) divided by the sum of their corresponding exposure times. These points
are the actual data we receive. Results from running Algorithm \ref{alg:gibbs}
are shown in the middle and right panels of Figure \ref{f:toy_calib_pois}.
Similar to the results in Figure \ref{f:toy_calib}, it is clear that the sampler
searches a broad swath of the model input space but hones in on the region where
the true parameter values lie.
\begin{figure}[ht!]
\centering
\includegraphics[scale=0.55,trim=20 0 30 0,clip=TRUE]{logit1_pois_obs.pdf}
\includegraphics[scale=0.55,trim=59 0 30 0,clip=TRUE]{logit1_pois_est.pdf}
\includegraphics[scale=0.55,trim=16 0 30 0,clip=TRUE]{logit1_pois_post_draws.pdf}
\caption{An inverse problem for a Poisson process. Counts observed in the field
and a sample of computer model runs (left), model evaluations at posterior
draws and mean (middle), and posterior distribution of model parameters
(right).
\label{f:toy_calib_pois}}
\end{figure}

In each of these examples we have made the assumption that we have unlimited
access to simulator runs (i.e, for each proposed combination of model
parameters, we can quickly get a response from the computer simulation). But
that is rarely the case, presenting another challenge to the typical Bayesian
inverse problem apparatus. For instance, each run of the IBEX model $m(\cdot,
\cdot)$ is a Herculean effort, requiring hundreds or thousands of core hours on
a supercomputer.  That simply cannot be embedded in a Metropolis sampler
requiring thousands of iterations to convergence.  While it's rather
conventional to deploy a surrogate model \citep[e.g.][]{gramacy2020surrogates}
in this setting, trained on a design of space-filling $u$-values, doing so
effectively is challenged by the dimension of $X^F$.  We considered multiple
surrogate models developed to accomodate such scenarios (e.g. GPs via inducing
points \citep{banerjee2008gaussian}, local approximate GPs
\citep{gramacy2014lagp}), but found them unable to manage the scale of the IBEX
data. Herein lies our main methodological contribution, using a modern sparse
approach to surrogate modeling in a (Poisson) Bayesian inverse problem setting.
The remainder of this section outlines the standard surrogate modeling toolkit,
as a jumping-off point toward explaining both our main comparative (Section
\ref{sec:gp_approx}) and our main methodological contribution.

%------------------------------------------------------------------------------
%% SECTION 2.2 - Gaussian Process Surrogates for Computer Experiments:
\subsection{Gaussian process surrogates for computer experiments}
\label{sec:gp_surr}
%------------------------------------------------------------------------------

%% GAUSSIAN PROCESS SURROGATES
%% - What is the motivation? Expensive computer experiments
%% - Set of n observations that follow a MVN
%% - Often mean-zero. In practice this means subtracting off the mean
%% - Results in all the action being in the covariance function
%% - Covariance depends on pairwise distance
%% - Explain some different kernels
%% - Talk about prediction. Show Kriging equations
%% - Nonparametric, flexible regression tool
%% - A lot of different applications
%% - Become popular in computer experiments because of interpolation
%% - This is what we want
%% - Bottleneck is O(n^3)
%% - LEAD IN: Output can be large. Need an approximation.
%% Review Gaussian processes and their use in surrogate modeling

Evaluating the likelihood $Y_F$ in Algorithm \ref{alg:gibbs} may proceed via
surrogate when {\em in situ} evaluation directly on $m(\cdot, \cdot)$ is too
slow. Suppose we have a vector of observations $Y^M$ at input locations $X^M$
from a campaign of runs of $m(\cdot, \cdot)$ that may or may not coincide with
settings in $X^F$. We prefer a small design of space-filling $u$-values ($U$),
paired via Cartesian product with $X^F$ from the field experiment or a
predictive grid $X$, e.g., $X^M = X \otimes U$, depending on the situation.
Two such runs, i.e., for two rows $u^\top \in U$ and a dense grid $X$, are shown
in Figure \ref{f:fig1}.

Given a corpus of runs $(Y^M, X^M)$, a surrogate synthesizes this information
in order to extend it to new inputs.  Many surrogates for computer
simulations are based on Gaussian processes
\citep[e.g.,][]{rasmussen2003gaussian}, where modeling boils down to
specifying a multivariate normal (MVN) for all responses.  This way,
prediction is simply a matter of MVN conditioning rules, or {\em kriging}
\citep{matheron1963principles}, to derive the distribution of unknown
(testing) output given known (training) values. Specifically, let $Y^M
\sim \mathcal{N}_{n_m}(\mu(X^M), \Sigma(X^M))$, where $\mathcal{N}_{n_M}$
indicates an $n_M$-variate MVN. Then, predicting at a new location $x$ (think
proposed $u$-value and paired row in $X^F$) follows $Y(x) \mid Y(X^M) \sim
\mathcal{N}(\hat{\mu}(x), \hat{\sigma}^2(x))$, where
\begin{align}
\hat{\mu}(x) &= \mu(x) + \Sigma(x, X^M) \Sigma(X^M)^{-1} (Y^M - \mu(X^M)) \label{eq:mvn_eq}\\
\hat{\sigma}^2(x) &= \Sigma(x, x) - \Sigma(x, X^M) \Sigma(X^M)^{-1} \Sigma(X^M, x). \nonumber
\end{align}
Although a generic mean function is specified in Eq.~(\ref{eq:mvn_eq}), it is
common to set $\mu(\cdot)=0$ assuming pre-centered responses. In this zero-mean
context, all the action takes place in the covariance function $\Sigma(x, x')$,
which is usually specified as inversely poportional to distances between inputs
$x$ and $x'$. We use a form known as the separable Mat\'ern kernel
\citep{stein1999interpolation} in our work, a conventional choice, parameterized
by lengthscales $\theta$ and scale $\tau^2$. For details, see \citep[][Chapter
5]{gramacy2020surrogates}. GPs provide a flexible, nonparametric regression
tool. In addition to enjoying canonical status as surrogates for computer
simulation experiments, they are utilized in geospatial statistics
\citep{cressie2011statistics}, time series \citep{roberts2013gaussian}, and
optimization \citep{jones1998efficient}.

GP surrogates are extremely effective. To illustrate, recall Figures
\ref{f:toy_calib} and \ref{f:toy_calib_pois} in Section \ref{sec:gen_bayes_inv},
where limited samples of computer model evaluations ($n < 50$) are shown. For
these toy examples, we ``assumed'' we had unlimited access to the simulator. In
reality, we fit a GP surrogate to the model runs in the left panels. Therefore,
``model runs'' at posterior draws of $u$ in the center panels are not in fact
evaluations of the model, but predictions from a fitted GP surrogate. Even so,
the Metropolis sampler used those accurate (and fast) predictions to
successfully recover the true model parameters $u^*$.

One downside to working with MVNs whose dimension grows with the dimension of
the data they are trained on, $n_M$, is that building $n_M \times n_M$ matrices,
and inverting (or otherwise decomposing) them, e.g., for Eq.~(\ref{eq:mvn_eq})
requires storage and computation that is quadratic and cubic in $n_M$,
respectively.  This limits $n_M$ to a few thousand at most in a Bayesian MCMC
setting, necessitating approximations for GPs that curb this prohibitive cost.
Further complicating this example is the density of the predictive grid $X$,
resulting in a large input matrix $X^M = X \otimes U$. Consider the
high-resolution simulated \textit{sky maps} in the middle and right panels of
Figure \ref{f:fig1}. The two degree grid over latitude and longitude (under the
hood the output is in spherical coordinates $x$, $y$, and $z$) results in ($>
16{,}000$ locations, or pixels) for each $u$-value. Combine that with $n=66$
unique $u$-values and our response vector will have greater than one million
elements. Even if we used a smaller LHS space-filling design of size $n=15$ over
the model parameters, the response vector would still consist of over 200,000
points. In that case, a GP could not be fit and provide predictions in a
reasonable amount of time, prompting the next topic.

%------------------------------------------------------------------------------
%% SECTION 2.3 - Approximations
\subsection{Approximations}
\label{sec:gp_approx}
%------------------------------------------------------------------------------

Most of our modeling effort in this paper involves circumventing the $O(n^3)$
computational bottleneck associated with GPs. The prevalence of methods
addressing this issue has grown significantly in the past decade as increased
access to computing resources leads to problems with larger and larger training
datasets. These methods include, but are not limited to, fixed-rank kriging
\citep{cressie2008fixed}, inducing points \citep{banerjee2008gaussian},
compactly supported kernels \citep{kaufman2011efficient}, divide-and-conquer
\citep{gramacy2015local}, and nearest neighbors \citep{datta2016hierarchical,
wu2022variational}. Most of these are general enough to be used in a variety of
different fields and applications. However, there is a method tailor-made for
our Bayesian inverse problem setting when the likelihood (for $Y_F$) is
Gaussian.

In the early 2000s, \citet{higdoncalib2008} faced challenges much like the IBEX
simulator. Not only were the computer models they worked with similarly
expensive, producing a limited number of runs, but their output was also
extremely high-dimensional, in the form of images, shape description, time
series, etc. Even with today's computing resources, it would be prohibitive to
fit a GP surrogate model on such large data. \citeauthor{higdoncalib2008}'s key
insight involved treating $X^F$ (or gridded $X$) -- i.e., the fixed reference
set that a simulator realization is evaluated on for each candidate parameter
$u$ -- as a feature of {\em output}, rather than conventionally an input. As a
result, model and field data share the same set of measurement locations, that
is, $X = X^F$. In this way, $X^M$ remains small, including only the unique
combinations of unknown parameters $u$.

Then, rather than keep track of all of those outputs $Y^M$, indexed over $X^F$
or $X$, dimensionality may be drammatically reduced via principal components
analysis (PCA). Specifically, they proposed representing the vector output of
a simulator model $m(\cdot,\cdot)$ as the sum of $n_k$ basis functions $k_1,
k_2, \ldots , k_{n_k}$, each scaled by a corresponding weight $w_i(u)$.
\begin{equation}
m(u, X) \approx \sum_{i=1}^{n_k}  k_i \cdot w_i (u),
\quad \mbox{ where } \quad w_i(u) \sim \mathcal{N}( 0, \Sigma_{w_i}) 
 \quad \mbox{and} \quad n_k \ll n_X.
\label{eq:higdon_pca}
\end{equation}
Weights $w_i(u)$ are each modeled as realizations of a zero-mean GP. By not
directly modeling the high-dimensional response $m(\cdot,\cdot)$ and it's
associated dense grid $X$, requesite decompositions $\Sigma_{w_i}$ avoids the
cubic bottleneck in computation when scaling to large $n$ and can be completed
in a reasonable amount of time.

While clever, this is one of those easy-to-say hard-to-do situations. The
implementation is complex both mathematically, and in code.  We are aware of
only one library implemenation, originally written in {\sf MATLAB} and now
deployed in {\sf Python} \citep{gattiker2020lanl},  We found it difficult to
approporiate that setup for our own use in a Poisson likelihood context.
Addtionally, restricting the simulated and field data to work on the same
reference grid was not possible with IBEX's orbital data locations (Figure
\ref{f:fig1}). Fortunately, GP approximation has come a long way in the last
twenty or years. \citeauthor{higdoncalib2008} specifically lamented not having
access to such technology, necessitating a more complex approach. It is no
longer necessary to play the trick of moving a reference grid to the output
space.  A GP (approximation) may model $Y^M$ via all inputs $X^F$ and $U$ via
$X^M$, as we shall demonstrate next.  The result is at once more modern, faster,
and better compartmentalized for use in novel contexts, such as our own.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%------------------------------------------------------------------------------
%% SECTION 3 - Vecchia Approximation
\section{Vecchia Approximation}
\label{sec:vecchia}
%------------------------------------------------------------------------------

In 1988, \citeauthor{vecchia1988estimation} proposed an approximation for
evaluating the multivariate normal likelihood. The Vecchia approximation relies
on the ability to write the likelihood function  as the product of univariate
normal conditional likelihoods, as displayed in Equation \ref{eq:vecchia}.
\citeauthor{vecchia1988estimation}'s critical observation was that one could
approximate this function by reducing the size of the conditioning set $g(i)$ to
a much smaller size $m$, as specified by the user. This induces sparsity (i.e, a
lot of zero entries) in the precision matrix (e.g. $\Sigma(X^M)^{-1})$ from
Eq.~\ref{eq:mvn_eq}), potentially dramatically speeding up the evaluation of the
likelihood for large values of $n$. \citet{katzfuss2021general} recently made
this approximation popular by working out its representation in matrix form,
allowing for broad use in a variety of different fields, particularly spatial
statistics and computer experiments
\citep{katzfuss2020vecchia,katzfuss2021general,zhang2022multi,sauer2023vecchia}.
\begin{align}
L(Y^M)&=\prod_{i=1}^n L(Y^M_i \mid Y^M_{g(i)})
\hspace{0.3em} \mbox{ where } g(1)=\emptyset \hspace{0.3em} \mbox{ and } g(i)=\{1, 2,
\ldots, i-1\} \nonumber \\
&\approx \prod_{i=1}^{n}L(Y^M_i \mid Y^M_{h(i)}) \hspace{0.3em} \mbox{ where } h(i)
\subset \{1, 2, \ldots, i-1\} \hspace{0.3em} \mbox{ and } |h(i)| = m \ll n
\label{eq:vecchia}
\end{align}

The Vecchia approximation takes an operation of order $O(n^3)$ down to
$O(nm^3)$, motivating small values of $m$. Logically, as the size of $h(i)$
decreases, the evaluation of the likelihood speeds up, but the quality of the
approximation is reduced. On the flip side, as one increases $m$, execution time
grows, but the degree of accuracy improves. This continues until $n=m-1$, when
the likelihood is no longer an approximation. For the IBEX simulator data, we
find a value of $m < 30$ to be more than sufficient, but the choice can be
impacted by the nature of the data and one's computational budget. Figure
\ref{f:ibex_vecchia} illustrates examples of varying sizes of conditioning sets
for a particular observation from the IBEX computer model. Note that more points
are concentrated near the reference point in latitude and longitude, whereas the
neighborhood is more spread out over the unknown model parameters. We elaborate
on the impetus for this behavior in the next section. The conditioning set can
be constructed in many ways, first by how the data itself is ordered, and
second, by how neighbors are selected. Many different orderings have been
proposed \citep{guinness2018permutation}, such as a maxi-min distance strategy.
We default to a random ordering of the training data and nearest-neighbors
approach for selecting the conditioning, taking a page from previous
implementations \citep{sauer2023active,cooper2025modernizing}, which yields
successful results, as we shall demonstrate shortly.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.4, trim=0 0 0 0,clip=TRUE]{ibex_nbr_latlon.pdf}
\includegraphics[scale=0.47, trim=0 0 0 0,clip=TRUE]{ibex_nbr_params.pdf}
\caption{Conditioning sets $h(i)$ in a multivariate normal likelihood
(Eq.~\ref{eq:vecchia}) for a single observation $y_i^M$ using the Scaled Vecchia
approximation. The left panel visualizes neighborhoods in grid space (i.e. $X$
or $X^F$). Model parameter ($u$) space is displayed in the right panel. For each
$h_j(i)$, all points from conditioning sets where $m < m_j$ are also included in
$h_j(i)$.
\label{f:ibex_vecchia}}
\end{figure}


%------------------------------------------------------------------------------
%% SECTION 3.1 - Scaled Vecchia Approximation
\subsection{Scaled Vecchia Approximation}
\label{sec:vecchia_ex}
%------------------------------------------------------------------------------

Several implementations of the Vecchia approximation exist, but we employ one
that has risen to the top in terms of predictive performance and computational
thriftiness in the context of computer experiments, that is, the Scaled
Vecchia approximation introduced by \citet{scaledvecchiakatzfuss2022}. We
refer you to their paper for a more in-depth explanation of their work. But,
the main crux of this implementation is the pre-scaling of inputs by dimension
before the creation of conditioning sets based on nearest neighbors.
\citet{scaledvecchiakatzfuss2022} point out that dimensions affect the
response differently and at varying rates and therefore predictions should be
made based on neighborhoods that account for this heterogeneity in each
dimension's impact. Scaling the data beforehand addresses this. Publicly
available code for this implementation that we directly rely on is readily
accessible at \url{https://github.com/katzfuss-group/scaledVecchia}.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.5,trim=5 38 65 0,clip=TRUE]{ibex_sim_pmfp_1500_0.005.pdf}
\includegraphics[scale=0.5,trim=35 38 65 0,clip=TRUE]{ibex_sim_pmfp_1625_0.005.pdf}
\includegraphics[scale=0.5,trim=35 38 65 0,clip=TRUE]{ibex_sim_pmfp_1750_0.005.pdf}
\includegraphics[scale=0.5,trim=5 38 65 0,clip=TRUE]{ibex_sim_pmfp_1500_0.0075.pdf}
\includegraphics[scale=0.5,trim=35 38 65 0,clip=TRUE]{ibex_sim_pmfp_1625_0.0075.pdf}
\includegraphics[scale=0.5,trim=35 38 65 0,clip=TRUE]{ibex_sim_pmfp_1750_0.0075.pdf}
\includegraphics[scale=0.5,trim=5 0 65 0,clip=TRUE]{ibex_sim_pmfp_1500_0.01.pdf}
\includegraphics[scale=0.5,trim=35 0 65 0,clip=TRUE]{ibex_sim_pmfp_1625_0.01.pdf}
\includegraphics[scale=0.5,trim=35 0 65 0,clip=TRUE]{ibex_sim_pmfp_1750_0.01.pdf}
\caption{Simulated and predicted outputs from the IBEX \textit{sky map}
computer model. Corner panels represent the response for four unique
combinations of model inputs. Panels on the cross with bold, dashed borders
are predictions from a GP surrogate fit to $n=66$ runs of the computer model.
Model parameter settings for the predictive panels fall between the four
simulated runs shown.
\label{f:ibex_sim_surr}}
\end{figure}

Next we assess the Scaled Vecchia approximations performance on the IBEX
simulator, first with a visual example. We have access to 66 model runs, each
producing an image of 16,200 points or pixels. Figure \ref{f:ibex_sim_surr}
shows four of the actual simulation outputs (corner panels displayed with thin,
solid borders). A Scaled Vecchia GP surrogate was fit to all 66 simulated runs.
Then, we predict the output for five unobserved combinations of the model
parameters that fall in between the actual runs shown. These are depicted in
the cross of Figure \ref{f:ibex_sim_surr}, those panels with thick, dashed
borders. To the naked eye, these predictive surfaces appear to have been
generated by the simulator itself. Moving left to right, or top to bottom, the
surfaces change gradually and as one would expect. But we are not satisfied
with simply passing the eye test, so we turn to empirical results and show that
our surrogate fit is extremely accurate and outperforms other current methods.

%------------------------------------------------------------------------------
%% SECTION 3.1.1 - Assessing predictive accuracy
\subsubsection{Assessing predictive accuracy}
\label{sec:surr_accuracy}
%------------------------------------------------------------------------------

In order to validate performance of our surrogate model, we conduct a simple
hold-one-out experiment. For each iteration of this bakeoff, we fit a Scaled
Vecchia approximated GP surrogate on 65 of the $n=66$ model runs available.
Then, we predict at the held out combination of model parameters. We then
evaluate how well the model did with two metrics, root mean square error (RMSE)
and the continuous ranked probability score (CRPS) proposed by
\citet{gneiting2007strictly}. For the purpose of comparison, we execute the
same test for three other competitors: {\sf R} packages {\sf laGP}
\citep{gramacy2014lagp} and {\sf deepgp} \citep{deepGP}, and the current
``status-quo,'' SEPIA \citep{gattiker2020lanl}, implemented in {\sf Python}.
Figure \ref{f:ibex_surr_metrics} displays the results of this bakeoff.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.45, trim=0 0 0 0,clip=TRUE]{ibex_surr_rmse.pdf}
\includegraphics[scale=0.45, trim=0 0 0 0,clip=TRUE]{ibex_surr_crps.pdf}
\caption{Metrics on the IBEX simulator experiment. Smaller is better for both
RMSE and CRPS.
\label{f:ibex_surr_metrics}}
\end{figure}

For now, just pay attention to left-hand side of each panel, where $pc=3$ for
the SEPIA boxplots and $m=25$ for the Scaled Vecchia boxplots. We'll come back
to the others in a moment. It's clear that the Scaled Vecchia approximation
outperforms {\sf laGP} and {\sf deepgp} in both RMSE and CRPS. We gave {\sf
laGP} the default neighborhood size of 50, but the predictions are made based
only on observations local to the predictive location, perhaps preventing
understanding of global trends in the surface. {\sf deepgp} is fully Bayesian,
utilizing MCMC to sample from the posterior distribution. But that comes with a
cost. Because of the significant computational burden, we were only able to run
1000 MCMC iterations, burning in 500 and thinning by 10, along with the
built-in Vecchia approximation with a conditioning set size of $m=10$. Even
with these limitations, {\sf deepgp} took a considerable amount of time, and
likely contributed to it's poor performance. SEPIA performed similarly to our
Scaled Vecchia approximation, illustrating why it has had such staying power
over the past two decades. As a practitioner, it appears to be a toss-up
between these two methods for which to use. But that's not the entire story.

%------------------------------------------------------------------------------
%% SECTION 3.1.2 - Assessing computational expense
\subsubsection{Assessing computational expense}
\label{sec:surr_timing}
%------------------------------------------------------------------------------

% Additionally, the number of runs can be varied, based on the
% expense of a simulation run. To evaluate this, we conducted two more
% experiments.

In addition to assessing accuracy and uncertainty quantification through RMSE
and CRPS, we aimed to evaluate the speed of execution for all competitors
involved. Two factors exist that contribute to a computational bottleneck.
First, the dimension of the simulator response, which has been the main focus
of our work. To test this, we modified the dimensionality of the response from
200 to 20,000, while keeping the number of runs constant. For the two methods
that are most equipped for large dimensions (Scaled Vecchia and SEPIA), we
attempt to stretch their capacity by cranking up the length of the response
vector from 20-75K, by 5K. At each dimension size, we ran five Monte Carlo
iterations with each method.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.57, trim=0 0 0 0, clip=TRUE]{ibex_surr_fit_times.pdf}
\includegraphics[scale=0.57, trim=0 0 0 0, clip=TRUE]{ibex_surr_pred_times.pdf}
\includegraphics[scale=0.57, trim=0 0 0 0, clip=TRUE]{ibex_surr_total_times.pdf}
\caption{Timing metrics on the IBEX simulator experiment.
\label{f:ibex_surr_timing_dim}}
\end{figure}

Results in Figure \ref{f:ibex_surr_timing_dim} make it apparent that Scaled
Vecchia and SEPIA are both well-suited for increasing dimensionality in the
response. {\sf laGP}, while built for prediction with large-scale datasets, is
unable to keep pace at a certain point, likely due to the need to fit a
mounting number of local GPs. Reducing the neighborhood size (set to the
default of 50 in our experiment) for {\sf laGP} could certainly aid in the
computation expense, but that would further degrade it's performance, which
already lags being Scaled Vecchia and SEPIA (Figure \ref{f:ibex_surr_metrics}).
{\sf deepgp}'s need to decompose an $n \times n$ matrix at each MCMC iteration,
even aided by the Vecchia approximation, causes it's cost to quickly grows as
dimensionality expands. The comparison between Scaled Vecchia and SEPIA is more
nuanced. In the right panel of Figure \ref{f:ibex_surr_timing_dim}, we see that
for a fixed number of principal components, SEPIA's execution time increases
only slightly as dimension expands. For a fixed value of $m$, Scaled Vecchia's
runtime increases linearly with expanded dimensionality, as advertised by
\citet{katzfuss2021general}. However, for response dimension less than 75K,
Scaled Vecchia executes faster. Additionally, the IBEX simulator surface is not
particularly complex, allowing SEPIA to perform well with a low number of
principal components. That may not be the case in other situations, requiring a
heavier load. We'll see one more comparison that illustrates Scaled Vecchia's
superior performance in our next experiment.

%% NEXT EXPERIMENT
Next, we consider modifying the size of the training dataset (i.e, the number
of simulator runs). SEPIA was specifically built for computer experiments with
high-dimensional output. While it clearly performs well in these situations,
it's also fairly inflexible to other contexts, such as a large number of
simulation runs. Scaled Vecchia does not face this hurdle, as it treats both
high-dimensional output and large-scale univariate datasets similarly, as a
univariate response. We show this robustness in our next bakeoff. Our
experiment is set up similar to the previous one. But we keep the
dimensionality of the response at 10K, while sliding the number of simulator
runs from 10 to 100. Again, each method is run over five MC iterations for each
value of $n$. For the higher performing methods, we push the campaign size up
further up $n=2500$. Results are shown in Figure \ref{f:ibex_surr_timing_size}.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.57, trim=0 0 0 0, clip=TRUE]{ibex_surr_fit_times_ns.pdf}
\includegraphics[scale=0.57, trim=0 0 0 0, clip=TRUE]{ibex_surr_pred_times_ns.pdf}
\includegraphics[scale=0.57, trim=0 0 0 0, clip=TRUE]{ibex_surr_total_times_ns.pdf}
\caption{Timing metrics on the IBEX simulator experiment.
\label{f:ibex_surr_timing_size}}
\end{figure}

It's no surprise that {\sf deepgp} once again lags in run time. Even a modest
sized set of runs takes well over an hour to fit, and needs almost 10 minutes
to make one prediction. Most interesting is the behavior of SEPIA in the right
panel of Figure \ref{f:ibex_surr_timing_size}. For $n \gg 500$, SEPIA takes
hours to fit and make predictions. In this context, even {\sf laGP} performs
better. Our preferred method, Scaled Vecchia, shows consistency in scaling
linearly both with an increased campaign size, and increased dimensionality.
All of this illustrates the effectiveness of Scaled Vecchia, and that it's a
prime candidate for use in Bayesian inverse problems. In fact,
\citet{scaledvecchiakatzfuss2022} even suggested use of their method in this
context. We explore this next.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% SECTION 4: Simulated Sky Maps
\section{Simulated Sky Maps}
\label{sec:sims}

%% HELIOSPHERIC SCIENCE
%% - Short review of heliosphere
%% - Behavior of Energetic Neutral Atoms
Over the past 15 years, physicists have developed theoretical models
\citep{heerikhuisen2009pick,schwadron2013spatial,mccomas2017seven} to explain
the existence of the \textit{ribbon}, the process by which it is generated,
and it's corresponding shape and intensity. Dozens of theories emerged in the
few years immediately after the IBEX satellite was launched and began
returning data, and more have followed in the ensuing years. Different factors
that have been proposed to affect the shape and intensity of the
\textit{ribbon} include, but are not limited to, the extent to which hydrogen
ions in the solar wind are scattered, the number of interactions the ions have
with other particles, the makeup and affect of the interstellar magnetic
field, and additional secondary sources of ENAs.

Physicists engaged in this work have developed computer models to represent
the theoretical models they have proposed. Therefore, given specific values
for different model parameters, a simulation can be run to output a proposed
\textit{sky map}. As stated previously, Bayesian Inverse problems are
concerned with leveraging simulator output for the purpose of estimating the
distribution of model parameters. This is the primary interest of physicists
involved in this project, as estimation of these parameters will give credence
to what model best represents the data.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%------------------------------------------------------------------------------
%% SECTION 4.2 - Heliospheric Computer Model
\subsection{Heliospheric Computer Model}
\label{sec:helio_comp_model}
%------------------------------------------------------------------------------

%% HELIOSPHERE COMPUTER MODEL
%% - Introduce computer model
%% - Explanation of parameters in computer model
%% - Introduce the data from the computer model

In this paper, we make use of two models developed by scientists at LANL and
Princeton University. In these models, the shape and intensity of the GDF is
controlled by parameter3 and parameter4, and the shape and intensity of the
\textit{ribbon} is controlled by parallel mean free path and ratio. We leave a
more in-depth physical interpretation and analysis of these parameters to more
appropriate venues \citep{zirnstein2021dependence,zirnsteinGDFsims2015}.
However, for simple reasoning, one can think of the parallel mean free path as
the distance a hydrogen ion travels beyond the heliopause before interacting
with another particle, receiving an electron, and becoming an ENA. The ratio
parameter is closely related, being the fraction of perpendicular mean free
path and parallel mean free path. We can run this model and output a vector of
proposed ENA rates at specific spherical coordinates. The resolution of the
output can be varied, but typical runs output 16,200 rates, corresponding to a
2 degree grid over latitude and longitude.

We have access to $n=66$ runs of the simulator. These runs represent all
combinations of 11 unique values of parallel mean free path and 6 unique
values of ratio. The spread of parameter values was determined by the space
scientists to include all values considered reasonable. Parallel mean free
path ranges from 500-3000 astronomical units (AU) in increments of 500 AU.
Ratio values are unitless, and span from 0.001 to 0.1. Each computer model run
is executed on an identical grid over $x$, $y$, and $z$ (although all our
visuals will be shown after converting to geographical coordinates, latitude
and longitude).

In order to showcase and validate our proposed methodology on the IBEX data,
we will first test on simulated sky maps. To do this, we will treat one output
from the computer model simulation as the ``truth.'' Using this output as the
underlying mean ENA rate, we will draw Poisson counts with exposure time
specified by the real IBEX data. Figure \ref{f:ibex_synth_ex} shows both the
``truth'' from the simulation (top right) and the ``observed'' simulated data
(top left). Note that the locations of the simulated data are the recorded
coordinates for ENAs captured by the IBEX satellite in it's orbit. This
accounts for the unique spread of points and the strings of missing data,
which corresponding to certain orbits of the satellite.
\begin{figure}[ht!]
\centering
\includegraphics[scale=0.75,trim=0 0 65 0,clip=TRUE]{ibex_sim_mod.pdf}
\includegraphics[scale=0.75,trim=35 0 65 0,clip=TRUE]{ibex_sim_field.pdf}
\includegraphics[scale=0.75,trim=35 0 10 0,clip=TRUE]{ibex_sim_est.pdf}
\caption{IBEX simulator output of ENA rate at \textit{parallel mean free path}
$= 1750$ and \textit{ratio} $= 0.02$ (left). Rough estimate of simulated ENA
rate (counts/seconds) based on Poisson draws from ``truth'' in left panel and
varying exposure times (center). Predicted output via a fitted GP surrogate at
estimated calibration parameters \textit{parallel mean free path} $= 1675.61$
and \textit{ratio} $= 0.0178$ (right).
\label{f:ibex_synth_ex}}
\end{figure}
Now, treating the simulated data as if it came from the satellite, we run our
Poisson Bayesian Inverse Problem framework and estimate the underlying
parameters. In Figure \ref{f:ibex_synth_ex}, the bivariate posterior
distribution of parallel mean free path and ratio are displayed (bottom left).
We can see that our framework does a good job of obtaining the true
combination of parameters, with the posterior mode lying near the truth.
Additionally, the truth falls squarely in the 95\% credible interval. As a
sanity check, we take the value of each parameter at the posterior mode and
insert those into our fitted surrogate model. The predicted output is shown in
the bottom right of Figure \ref{f:ibex_synth_ex}. It is obvious that there are
some differences between the estimated sky map and the ``truth.'' The shape
and intensity of the ribbon in each sky map is slightly different. However, it
is also abundantly clear that each map (truth and estimated) could have
reasonably generated the data we ``observe''in the top left panel. Therefore,
we can confidently assert that our framework recovers the truth.

%------------------------------------------------------------------------------
%% SECTION 4.3 - Experiment
\subsection{Experiment}
\label{sec:ibex_sim_exp}
%------------------------------------------------------------------------------

%% EXPERIMENT
%% - Explain set up of the experiment
%% - Show results from simulated data
%% - Lead-in to real data

Before we get ahead of ourselves, we recognize that Figure
\ref{f:ibex_synth_ex} is just one data point. So, to further validate our
framework, we can apply this method to each unique combination of calibration
parameters within our simulator output. Due to the inability for the model to
provide good posterior distributions for boundary parameters, we do not
consider combinations for which at least one parameter is on its edge. For
instance, when parallel mean free path is either 500 or 3000 AU and/or ratio
is either 0.0001 and 0.1. Removing these edge cases results in 36 remaining
unique combinations. For each combination, we follow the same procedure as
described above. First, we elect one unique combination and create simulated
observed satellite data based on the computer model. Next, we remove that
combination from the training data used to fit our Scaled Vecchia Gaussian
Process surrogate model in our calibration framework. Finally, we run MCMC to
sample from the posterior distribution of our calibration parameters and
obtain an estimates for the posterior mean. Our results are shown in Figure
\ref{f:synth_estimates_all}. In each plot of the posterior distributions, we
have included as a blue star the true combination of parameters that generated
the simulated data. Our 95\% credible intervals encompass the truth in 34 of
the 36 of the iterations, near the nominal coverage rate we'd expect.

%%% Can we put something in here that shows using the computer model improves prediction
%%% over just modeling field data? Hard to do without spoiling my next paper?
% In addition to estimating the calibration parameters, we can utilize our framework to
% achieve better prediction at out-of-sample field locations. While we have not dealt
% with real data from the satellite just yet, we can simulate satellite data as before
% and run cross-validation on holdout sets.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.3,trim=0 0 0 0,clip=TRUE]{calib_estimates_all.png}
\caption{Posterior distributions for estimated calibration parameters for each unique
combination of values that has been treated as a holdout set.
\label{f:synth_estimates_all}}
\end{figure}

We have demonstrated that our framework can recover the true parameter values
that generated simulated data. However, space scientists are interested in
understanding the behavior of the heliosphere by estimating these parameters
for real data. So, the natural next step is to take our approach and apply it
to data actually observed by the IBEX satellite. This leads naturally into our
next section.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% SECTION 5: Real Data
\section{Real Data}
\label{sec:ibex_real}

%------------------------------------------------------------------------------
%% SECTION 5.1 - IBEX
\subsection{IBEX}
\label{sec:ibex}
%------------------------------------------------------------------------------

%% IBEX
%% - Reintroduce satellite
%% - Explain details of data
%% - Explain the years gathered

We have referred to the IBEX satellite throughout this paper without going
into immense detail of just how the data is collected. As stated previously,
while the IBEX satellite orbits Earth, the IBEX-Hi ENA imager detects ENAs and
records their energy level and approximate location of origin. ENAs can be
sorted into six distinct energy levels, labeled as ESA 1, 2, \ldots, 6. At
regular time intervals, the satellite is rotated slightly to point to a new
section of sky. These adjustments, along with the satellite's orbit, allows
IBEX to view the entire sky over a period of six months. Therefore, dating
back to 2008, we have access to $\sim$35 estimated \textit{sky maps}.

Add another paragraph.

%------------------------------------------------------------------------------
%% SECTION 5.2 - EXPERIMENT
\subsection{Experiment}
\label{sec:ibex_exp}
%------------------------------------------------------------------------------

%% EXPERIMENT
%% - Explain set up of the experiment
%% - Show results from the real data
%% - Comment on the missalignment between simulator and reality

Our setup is similar to that in Section \ref{sec:ibex_sim_exp}, only
substituting in real data for simulated data. Therefore, we execute Algorithm
\ref{alg:gibbs} by initially fitting a Scaled Vecchia GP surrogate to all
$n=66$ computer model runs. Then, MCMC samples from the posterior distribution
of our model parameters, evaluating the likelihood of the real data given the
surrogate predictions at new proposed parameter values. Some things of note
are that we only use satellite data collected during the years 2011-2013. This
comes recommended by the space scientists, as the models are developed to
reflect the behavior of the Sun and corresponding solar wind during that time
period. Additionally, we only use ENAs collected at energy level ESA 4. This
energy level allows the best context for analysis, whereas lower ESAs have a
much weaker signal and higher ENAs overwhelm the analysis.

Results are shown in Figure \ref{f:real_estimates_all}.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.3,trim=0 0 0 0,clip=TRUE]{calib_estimates_all.png}
\caption{Posterior distributions for estimated calibration parameters for each unique
combination of values that has been treated as a holdout set.
\label{f:real_estimates_all}}
\end{figure}

%------------------------------------------------------------------------------
%% SECTION 5.3 - DISCREPANCY
\subsection{Discrepancy}
\label{sec:ibex_discrep}
%------------------------------------------------------------------------------

%% DISCREPANCY
%% - Refer to KOH, Higdon, and their use of discrepancy
%% - Introduce simple scaling discrepancy (iniclude some equations)
%% - Refer to results in Appendix for simulated data where we discover the true scale
%% - Explain set up for IBEX calibration with discrepancy
%% - Show results
%% - Comment on complexity of discrepancy. Scale isn't sufficient.
%% - Perhaps a stationary GP is not even sufficient

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% SECTION 6: Discussion
\section{Discussion}
\label{sec:discuss}

We have introduced an effective tool for solving inverse problems using
Bayesian methods where 1) data from a field experiment is not normally
distributed and 2) computer model output is extremely high-dimensional,
demanding an approximation for the Gaussian process surrogate. In simulated
experiments, our framework provides accurate predictions at unsampled input
locations. Additionally, when provided with data where the underlying
calibration parameters are known, we can recover the truth at the nominal 95\%
rate. We applied this methodology to data collected from the IBEX satellite,
and corresponding simulator output generating heliospheric sky maps. When
faced with real data from the satellite, our method shows that large
discrepancies exist between the computer model and the physical process it
attempts to represent. Further collaboration is needed to inform the
theoretical astrophysicists responsible for model development where the model
is lacking, and improve its fidelity to the truth.

Our framework is only applied to counts assumed to come from a Poisson
distributed process. We encourage other practitioners to use this work in
other contexts where data from the field may come from some other distribution
(e.g. Negative Binomial, Bernoulli, Exponential, etc.). We recognize the
limitations of our method. First, the Scaled Vecchia GP surrogate for the
computer model fails to provide full uncertainty quantification on its
parameter estimates. A fully Bayesian framework could be developed, perhaps
with the use of a deep Gaussian process to handle the inherent
non-stationarity in the response surface. Finally, this project motivates the
need for a more exhaustive procedure to perform hypothesis testing for which
theoretical model is most probable, considering the data observed.

\subsection*{Acknowledgments}

RBG and SDB are grateful for funding from NSF CMMI 2152679. This work has been
approved for public release under LA-UR-XX-XXXX. SDB, DO and LJB were funded
by Laboratory Directed Research and Development (LDRD) Project 20220107DR.

\bibliography{ibex_bayes_inv}
\bibliographystyle{jasa}

\appendix

\end{document}
