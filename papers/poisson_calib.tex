\documentclass[12pt]{article}
\usepackage[ruled, vlined]{algorithm2e}
\usepackage{amsmath, amsfonts, amssymb, mathrsfs}
\usepackage{caption}
\usepackage{dcolumn}
\usepackage{filemod}
\usepackage{floatrow}
\usepackage{gensymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{natbib}
\usepackage{setspace}
\usepackage{subcaption}
\usepackage{verbatim}

\oddsidemargin=0.25in
\evensidemargin=0.25in
\textwidth=7in
\textheight=8.75in
\topmargin=-.5in
\addtolength{\oddsidemargin}{-.5in}
\addtolength{\evensidemargin}{-.5in}
\footskip=0.5in

\begin{document}

\title{Computer Model Calibration for Spatially Distributed
Counts} \author{Steven D. Barnett\thanks{Corresponding author
\href{mailto:sdbarnett@vt.edu}{\tt sdbarnett@vt.edu}, Department of Statistics,
Virginia Tech} \and Robert B. Gramacy\thanks{Department of Statistics, Virginia
Tech} \and Lauren J. Beesley\thanks{Statistical Sciences Group, Los Alamos
National Laboratory} \and Dave Osthus\footnotemark[3] \and Yifan Huang\thanks{
Nuclear and Particle Physics, AstroPhysics and Cosmology, Los Alamos National
Laboratory} \and Fan Guo\footnotemark[4] \and Eric J. Zirnstein\thanks{
Department of Astrophysical Sciences, Princeton University} \and Daniel B.
Reisenfeld\thanks{Space Science and Applications Group, Los Alamos National
Laboratory}}

\date{\today}

\maketitle

\vspace{-0.5cm}

\begin{abstract}
The Interstellar Boundary Explorer (IBEX) satellite detects energetic neutral
atoms (ENAs) and determines the rate at which they are generated in the
heliosphere. Computer models attempt to represent the physical process that
produces heliospheric ENAs through specified model parameters. Computer model
calibration enables statisticians to use data collected in a field experiment
along with simulator output from a variety of parameter settings to make
out-of-sample predictions and learn the posterior distributions of model
parameters. However, calibration typically assumes a Gaussian or continuous
response for both field and computer model data. We introduce a novel Markov
chain Monte Carlo calibration framework that accommodates the spatially
distributed Poisson counts collected by the IBEX satellite. Additionally, the
computer simulation in our application is limited in the amount of runs it can
perform, but each run's output is quite large. Therefore, we propose the use of
the Scaled Vecchia approximation as a Gaussian process (GP) surrogate. We
demonstrate the capability of our proposed framework through multiple simulated
examples and show that we can consistently recover the true parameters in a
discrepancy-free environment and obtain accurate out-of-sample prediction. We
apply this to the IBEX satellite data and the corresponding computer model
output.

\bigskip
\noindent \textbf{Key words:} computer experiments, simulator, Gaussian process
 surrogate, ordinal response, Vecchia approximation, Bayesian inference,
 heliospheric science, IBEX
\end{abstract}

\doublespacing % no double spacing for arXiv

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
\label{sec:intro}

The solar wind, continously emitted from the Sun, is primarily made up of
hydrogen ions, or lone protons. These ions travel through the solar system and
out into interstellar space. The heliosphere is an egg-shaped bubble
encompassing our solar system that is formed from these hydrogen ions, acting
as a barrier between our solar system and interstellar space. As the ions reach
the boundary of our solar system, they encounter the termination shock, where
they slow down, absorb significant amounts of energy, and become highly
energetic, charged atoms. While in this region called the heliopause (the outer
edge of the heliosphere), the ions can interact with other particles in the
interstellar medium. Sometimes these encounters result in electron exchange,
converting the charged atoms into what heliospheric physicists call energetic
neutral atoms (ENAs). Without charge, these ENAs travel in a straight line,
unaffected by magnetic fields. Some ENAs cross back into the solar system and,
depending on their path, can be detected in Earth's orbit. Determining the rate
at which ENAs are generated in different parts of the heliosphere is key to
understanding the makeup of this region at the boundary of our solar system and
interstellar space.

In this pursuit, the National Aeronautics and Space Administration (NASA)
launched the Interstellar Boundary Explorer (IBEX) into Earth's orbit in 2008
as part of their Small Explorer program \citep{mccomas2009aIBEX}. IBEX
continuously detects ENAs and records their energy level and approximate
location of origin, providing data to estimate the rate at which ENAs are
created throughout the heliopause. Specifically, the IBEX satellite contains an
instrument called the IBEX-Hi ENA imager \citep{funsten2009IBEXHiENA}, which
includes a series of plates that the ENAs travel through to be detected. The
IBEX satellite rotates on an axis, and over a period of six months, is able to
point at every part of the sky for a certain amount of time. This spatial map
of ENA rates (referred to by space scientists as a \textit{sky map}) is used to
analyze, make conjectures about, and ultimately develop theories for the
heliosphere, its many properties, and the processes that govern its creation.

The heliosphere is like a boat moving through water. Here the water represents
the interstellar medium. As a boat moves through water, the water is disturbed.
However, the turbulence created is not equal at each location where the boat is
in contact with the water. Turbulence is greater at the bow (front) and stern
(back) than on the sides (port and starboard) of the ship. Prior to the launch
of the IBEX satellite, space scientists had the same expectation for the
heliosphere. Higher rates of ENAs being generated would exist at the stern
(space scientists call this the \textit{nose}) and bow (\textit{tail}) of the
helisophere due to its movement through interstellar space. Data observed found
this to be true. These higher rates are referred to as \textit{globally
distributed flux (GDF)}. But in a completely unexpected finding
\citep{mccomas2009bIBEX}, IBEX also recorded a string of higher rates of ENAs
\citep{fuselier2009IBEXribbon} being generated that curved around the
heliosphere. Scientists now refer to this phenomenom as the \textit{ribbon}.
For the past fifteen years, space scientists have conducted extensive research
and proposed dozens of theories to explain the existence of the ribbon and the
physical process that generates it (\citep{mccomas2014ibex, zirnstein2018role,
zirnstein2019strong, zirnstein2021dependence}.

%%% No calibration going on in IBEX (super novel)
Scientific investigation of the GDF and ribbon currently involves a long,
complex, and at times cumbersome process. For one, the noisy and irregular
nature of the data has made it hard for space scientists to separate signal
from noise and perform their analyses. For the first 15 years of its mission,
IBEX relied soley on maps produced by the IBEX Science Operations Center
(ISOC). To generate these ISOC maps, simple aggregation of the raw data is
done. But ISOC maps still retain a significant amount of noise and are fairly
low resolution (each pixel represents a $6\degree \times 6\degree$ portion of the
sky). To remedy this problem \citet{osthustheseus2023} propose a method called
Theseus, which takes the raw data and generates a much smoother representation
of the surface, using a series of Generative Additive Models (GAM) and
Projection Pursuit Regression. Once Theseus maps are created, they are
separated into GDF-only and ribbon-only maps \citet{beesleyribbonsep2023}. With
the source of ENAs separated into two distinct maps, space scientists perform
analysis and conduct research exclusively for either the GDF or ribbon with the
respective map. However, both Theseus and ribbon separation rely on many
assumptions about the data and thus depart from the data generation process
itself.

% Introduce existence of computer model simulations (ribbon, GDF).
In conjunction with proposing explanations for the existence of the ribbon and
GDF, theoretical physicists have develped computer models to simulate the
creation of sky maps. These computer simulations rely on a number of parameters
that can be varied, thus modifying the shape and intensity of both ribbon and
GDF. Although many simulations exist, we focus on two that are publicly
available: a GDF model proposed by \citet{zirnsteinGDFsims2015} that relies on
two parameters, param1 and param2, and \citet{zirnsteinGDFsims2015}'s model
that generates ribbon maps representative of the Spatial Retention model,
relying on two parameters, parallel mean free path and ratio. So far, minimal
work has been done to further understand the heliosphere by pairing the
computer model output with real data collected by IBEX computer models.

Statistical computer model calibration utilizes both data collected from a
physical experiment and data generated from a computer simulation
representative of the physical process of interest. Often, the physical
experiment is either too expensive to run a sufficient number of times or it's
unethical to conduct. In this way, a computer model representing the physical
process allows a practitioner to learn more about the physical process without
the prohibitive expense. Use of this additional source of data (even with its
potential bias) has been shown to improve prediction and uncertainty
quantification out-of-sample. It is often impossible to control the values of
certain variables in a physical experiment (e.g. gravity), but that barrier
does not exist in a computer simulation. These calibration or tuning parameters
can be of high scientific interest. Varying them helps experimenters explore
more of the input space, understand the distribution of these parameters, and
perhaps make inferential claims about them. Parameters that are part of
computer simulations developed by space scientists to explain the existence of
the GDF and ribbon fall in this category.

Computer experiments \citep{santner2003design} do not face the same ethical and
practical obstacles of physical experiements. Although some simulations are
very quick to evaluate \citep{higdoncalib2004}, frequently they can be
expensive in terms of compute time. Some computer simulations take hours, or
even days, to complete. In our case, an individual run of the IBEX computer
model to produce a simulated sky map can take up to 16 hours, precluding the
assumption of an infinite supply of model data. Because of this constraint, a
GP surrogate \citep{sacks1989computerexp, gramacy2020surrogates} is often fit
to the limited computer output in order to provide faster predictions out of
sample. Adding another layer of complexity, the output from the IBEX simulation
is not only expensive to obtain, but is extremely high dimensional. Each run of
the simulation produces a sky map represented by a vector of 16,200 ENA rates.
The computational burden of inverting a large covariance matrix in a GP
surrograte necessitates approximation. \citet{higdoncalib2008} rely on a basis
representation via principal components to reduce the dimension of the data.
But use of a basis representation was only necessary due to a lack of
computational ability, something that has changed in the past two decades.

% Introduce a charicature of the IBEX problem
Now, before we get ahead of ourselves, let's start with a simple problem.
Suppose we are given counts collected from a physical experiment at different
input locations ($x_i$), as shown in Figure \ref{f:logit1_examp}. We know that
the underlying mean process is of the form $\lambda_i=\mu + \nu f(x_i)$. We are
unable to modify $\mu$ and $\nu$ in a physical setting, but we can vary these
values in a trivial, one-line ``computer model.'' If we consider all unique
combinations for the values of $\mu \in \{5, 7.5, 10, 12.5, 15\}$ and $\nu \in
\{0.25, 0.625, 1, 1.375, 1.75\}$, we end up with 25 different functional
evaluations (depicted as gray lines in \ref{f:logit1_examp}). Our goal is
two-fold: 1) make accurate predictions at new, unobserved physial locations
($x_i'$) with good UQ, and 2) estimate the distribution of calibration
parameters $\mu$ and $\nu$ to better understand the how the mean process is
constructed.

\begin{figure}[ht!]
\centering
\includegraphics[scale=0.3, trim=5 15 15 50,clip=TRUE]{logit1_examp.pdf}
\caption{Physical observations of a Poisson process at varying $x_i$ locations
along with evaluations of $\lambda_i=\mu + \nu f(x_i)$ for different values of
$\mu$ and $\nu$.
\label{f:logit1_examp}}
\end{figure}

The canonical framework for statistical computer model calibration was proposed
by \citet{kennedyohagan2001}. However, \citet{kennedyohagan2001} (hereafter
referred to as KOH) relies on modeling the simulation runs and field data
jointly via a multivariate normal representation. The field data collected by
IBEX comes in Poisson-distributed as counts, preventing use of KOH. Previous
work has been done to generalize calibration to non-Gaussian responses
\citep{grosskopfcountcalib2020}. But empirical examples and applications in
this work are restricted to one-dimensional input spaces. Expanding to higher
dimensions brings with it multiple challenges, including the need to scale up
to larger datasets. No approximation method was necessary in
\citet{grosskopfcountcalib2020}'s implementation. As mentioned previously,
\citet{higdoncalib2008} employed PCA to reduce the dimensionality of the data.
We propose a modern approach using the Scaled Vecchia approximation
\citep{scaledvecchiakatzfuss2022}. In fact, the application of the Scaled
Vecchia approximation in the context of computer model calibration was
suggested by the authors themselves, noting its ability to scale well.
Therefore, our proposed framework allows for both large scale computer model
output and the ability to extend to any type of physical response. We focus on
Poisson-distributed data.

Our paper is outlined as follows: We review statistical computer model
calibration in Section \ref{sec:review} and focus on the use of GPs as
surrogates of computer simulations. Section \ref{sec:gen_calib} introduces a
novel Markov chain Monte Carlo framework (MCMC) as an extension of KOH to
account for non-Gaussian data \ref{sec:poisson_calib} in computer model
calibration. We finish Section \ref{sec:scale_vec} by introducing the Scaled
Vecchia Approximation \citep{scaledvecchiakatzfuss2022} as a way to account for
large-scale data in the computer model output. We illustrate the efficacy of
our method through empirical results for small and large problems in Section
\ref{sec:empir_results}. We finish our contribution through novel application
to the real IBEX satellite data in Section \ref{sec:ibex}. Section
\ref{sec:discuss} follows up and concludes our paper with a discussion. Code
reproducing all examples is provided at
\url{https://github.com/lanl/IBEX_Calibration}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Gaussian Process Surrogates for Computer Model Calibration}
\label{sec:review}

\begin{itemize}
  \item Review Gaussian processes and their use in surrogate modeling
  \item Review Kennedy O'Hagan framework
  \item Review Dave Higdon's SEPIA approach
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Generalized Computer Model Calibration}
\label{sec:gen_calib}

\begin{itemize}
  \item Rehash the need to update KOH to account for Poisson data
  \item Explain the use of a no-bias set up to initially prove the capability
  \item Briefly show the math behind this
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Poisson Counts Response}
\label{sec:poisson_calib}
\begin{itemize}
  \item Show diagram of updated framework (McMC with Poisson likelihood)
  \item What if we have unlimited runs of the simulation?? Dave's 2004 paper
  \item Set it up to have a Poisson response
  \item What if we need a surrogate? Computer model takes a long time to run
  \item Set it up to have a Poisson response, but now our data is limited
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Scaled Vecchia Gaussian Process Surrogate}
\label{sec:scale_vec}

\begin{itemize}
  \item Increase to large data example.
  \item Show inability of framework to fit surrogate without Vecchia
  \item Introduce Scaled Vecchia
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Estimation of calibration parameters}
\label{sec:calib_params}

\begin{itemize}
  \item Talk about IBEX interested in calibration parameters, not just prediction
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Empirical Evaluation}
\label{sec:empir_results}

\begin{itemize}
  \item Show results on toy datasets, both 1D, 2D, and 2D large data
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{IBEX Sky Map}
\label{sec:ibex}

\begin{itemize}
  \item Go in depth on development of GDF and ribbon computer models
  \item Explain the parameters that govern the computer model output
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Synthetic IBEX Data}
\label{sec:ibex_sim}

\begin{itemize}
  \item Run tests on noisy maps generated from known simulations
  \item Display distributions on calibration parameters that show the method
    is able to recover the truth
  \item Show prediction results on hold out data (RMSE? Score? Visual?)
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Real IBEX Data}
\label{sec:ibex_real}
\begin{itemize}
  \item Illustrate the gap between computer model output and real data
  \item Recall how we will account for discrepancy (PCA?, GP?)
  \item Perform tests on examples where we know what the bias is. How well
    does our method account for this?
  \item Lack of competitors? (could we compare to calibration of
    ribbon-separated maps)
  \item Run our code on IBEX real data.
  \item We could display predictions for different values of the calibration
    parameters. Not sure if this is of interest.
  \item Display distributions on calibration parameters.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion}
\label{sec:discuss}

\begin{itemize}
  \item Recap what we are proposing in the paper
  \item Highlight performance of calibration framework in prediction and
    estimation of calibration parameters
  \item Point out need to collaborate with theorists to improve computer
    model and get better estimates of calibration parameters
  \item Discuss a need to build out a more exhaustive procedure to perform
    hypothesis testing on which theoretical model is most probable to
    explain the data
  \item Acknowledge limitations (lack of fulll UQ with SVecchia estimates)
  \item Propose a fully Bayesian framework (teasing use of deep GPs)
  \item Can use in other non-Gaussian response settings
\end{itemize}

\subsection*{Acknowledgments}

RBG and SDB are grateful for funding from NSF CMMI 2152679. This work has been
approved for public release under LA-UR-??-?????. SDB, DO and LJB were funded
by Laboratory Directed Research and Development (LDRD) Project 20220107DR.

\bibliography{poisson_calib}
\bibliographystyle{jasa}

\appendix

\end{document}
